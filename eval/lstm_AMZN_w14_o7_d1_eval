2023-06-17 20:51:53{
    "alpha_vantage": {
        "api_key": "XOLA7URKCZHU7C9X",
        "output_size": "full",
        "url": "https://www.alphavantage.co",
        "key_adjusted_close": "5. adjusted close"
    },
    "data": {
        "train_test_split_size": 0.7,
        "train_val_split_size": 0.7,
        "smoothing": 2
    },
    "plots": {
        "show_plots": false,
        "xticks_interval": 90,
        "color_actual_val": "#001f3f",
        "color_actual_test": "#4D1BF3",
        "color_train": "#3D9970",
        "color_val": "#0074D9",
        "color_pred_train": "#3D9970",
        "color_pred_val": "#0074D9",
        "color_pred_test": "#FF4136"
    },
    "model": {
        "magnitude_1": {
            "lstm_num_layers": 4.5,
            "lstm_hidden_layer_size": 64,
            "drop_out": 0.4,
            "output_step": 1,
            "window_size": 14,
            "conv1d_kernel_size": 4,
            "dilation_base": 3
        },
        "LSTM_bench_mark_1": {
            "lstm_num_layer": 1,
            "lstm_hidden_layer_size": 64,
            "drop_out": 0.2,
            "output_step": 1,
            "window_size": 14
        },
        "GRU_bench_mark_1": {
            "hidden_size": 64,
            "output_step": 1,
            "window_size": 14
        }
    },
    "training": {
        "magnitude_1": {
            "device": "cuda",
            "batch_size": 64,
            "num_epoch": 1,
            "learning_rate": 0.001,
            "loss": "mse",
            "evaluate": [
                "mse",
                "mae"
            ],
            "optimizer": "adam",
            "scheduler_step_size": 50,
            "patient": 200,
            "from": "2021-01-01",
            "to": null,
            "best_model": true,
            "early_stop": true,
            "train_shuffle": true,
            "val_shuffle": true,
            "test_shuffle": true
        },
        "LSTM_bench_mark_1": {
            "device": "cuda",
            "batch_size": 64,
            "num_epoch": 1000,
            "learning_rate": 0.01,
            "loss": "bce",
            "evaluate": [
                "bce",
                "accuracy",
                "precision",
                "f1"
            ],
            "optimizer": "adam",
            "scheduler_step_size": 500,
            "patient": 1000,
            "start": "2000-5-01",
            "end": null,
            "best_model": true,
            "early_stop": true,
            "train_shuffle": true,
            "val_shuffle": true,
            "test_shuffle": true,
            "weight_decay": 0.1
        },
        "svm_1": {
            "batch_size": 64,
            "num_epoch": 300,
            "learning_rate": 0.01,
            "loss": "bce",
            "evaluate": [
                "bce",
                "accuracy",
                "precision",
                "f1"
            ],
            "optimizer": "adam",
            "scheduler_step_size": 50,
            "patient": 1000,
            "start": "2022-07-01",
            "end": "2023-05-01",
            "best_model": true,
            "early_stop": true,
            "train_shuffle": true,
            "val_shuffle": true,
            "test_shuffle": true,
            "weight_decay": 0.5
        }
    },
    "pytorch_timeseries_model_type_dict": {
        "1": "movement",
        "2": "magnitude",
        "3": "assembler",
        "4": "lstm",
        "5": "gru",
        "6": "ensembler",
        "7": "pred_price_LSTM"
    },
    "tensorflow_timeseries_model_type_dict": {
        "1": "svm",
        "2": "random_forest",
        "3": "xgboost"
    }
}
Epoch:11
Learning rate:11
{
    "model": {
        "num_layers": 10,
        "hidden_size": 20,
        "drop_out": 0.5,
        "conv1D_param": {
            "type": 1,
            "kernel_size": 4,
            "dilation_base": 3,
            "max_pooling_kernel_size": 2,
            "sub_small_num_layer": 1,
            "sub_big_num_layer": 1,
            "sub_small_kernel_size": 3,
            "sub_big_kernel_size": 30,
            "output_size": 20
        },
        "symbol": "AMZN",
        "topk": 10,
        "data_mode": 1,
        "window_size": 14,
        "output_step": 7,
        "max_string_length": 1000,
        "param_grid": {
            "data_mode": [
                0,
                1,
                2
            ],
            "window_size": [
                3,
                7,
                14
            ],
            "output_size": [
                3,
                7,
                14
            ],
            "drop_out": [
                0.0,
                0.2,
                0.5,
                0.8
            ],
            "max_string_length": [
                500,
                1000,
                10000,
                20000
            ]
        }
    },
    "training": {
        "device": "cuda",
        "batch_size": 64,
        "num_epoch": 50,
        "learning_rate": 0.001,
        "loss": "bce",
        "evaluate": [
            "bce",
            "accuracy",
            "precision",
            "f1"
        ],
        "optimizer": "adam",
        "scheduler_step_size": 50,
        "patient": 100,
        "start": "2022-07-01",
        "end": "2023-05-01",
        "best_model": true,
        "early_stop": true,
        "train_shuffle": true,
        "val_shuffle": true,
        "test_shuffle": true,
        "weight_decay": 0.0001
    }
}
Train evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.63      0.74      0.68        53
          UP       0.46      0.34      0.39        35

    accuracy                           0.58        88
   macro avg       0.55      0.54      0.54        88
weighted avg       0.56      0.58      0.56        88

Confusion matrix:
[[39 14]
 [23 12]]
----------------------------------------------------------------------------------------------------
Train evaluate lstm_AMZN_w14_o7_d1 BCE loss: 49.09183120727539
-----------------------------------------------------------------------------------------------------
Valid evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.54      0.76      0.63        17
          UP       0.71      0.48      0.57        21

    accuracy                           0.61        38
   macro avg       0.63      0.62      0.60        38
weighted avg       0.64      0.61      0.60        38

Confusion matrix:
[[13  4]
 [11 10]]
----------------------------------------------------------------------------------------------------
Valid evaluate lstm_AMZN_w14_o7_d1 BCE loss: 49.80112075805664
-----------------------------------------------------------------------------------------------------
Test evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.25      0.50      0.33        14
          UP       0.53      0.28      0.36        29

    accuracy                           0.35        43
   macro avg       0.39      0.39      0.35        43
weighted avg       0.44      0.35      0.35        43

Confusion matrix:
[[ 7  7]
 [21  8]]
----------------------------------------------------------------------------------------------------
Test evaluate lstm_AMZN_w14_o7_d1 BCE loss: 51.48900604248047
-----------------------------------------------------------------------------------------------------
Balanced Test evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.50      0.71      0.59        14
          UP       0.50      0.29      0.36        14

    accuracy                           0.50        28
   macro avg       0.50      0.50      0.48        28
weighted avg       0.50      0.50      0.48        28

Confusion matrix:
[[10  4]
 [10  4]]
----------------------------------------------------------------------------------------------------
Balanced Test evaluate lstm_AMZN_w14_o7_d1 BCE loss: 50.203041076660156
-----------------------------------------------------------------------------------------------------
2023-06-17 21:39:24{
    "alpha_vantage": {
        "api_key": "XOLA7URKCZHU7C9X",
        "output_size": "full",
        "url": "https://www.alphavantage.co",
        "key_adjusted_close": "5. adjusted close"
    },
    "data": {
        "train_test_split_size": 0.7,
        "train_val_split_size": 0.7,
        "smoothing": 2
    },
    "plots": {
        "show_plots": false,
        "xticks_interval": 90,
        "color_actual_val": "#001f3f",
        "color_actual_test": "#4D1BF3",
        "color_train": "#3D9970",
        "color_val": "#0074D9",
        "color_pred_train": "#3D9970",
        "color_pred_val": "#0074D9",
        "color_pred_test": "#FF4136"
    },
    "model": {
        "magnitude_1": {
            "lstm_num_layers": 4.5,
            "lstm_hidden_layer_size": 64,
            "drop_out": 0.4,
            "output_step": 1,
            "window_size": 14,
            "conv1d_kernel_size": 4,
            "dilation_base": 3
        },
        "LSTM_bench_mark_1": {
            "lstm_num_layer": 1,
            "lstm_hidden_layer_size": 64,
            "drop_out": 0.2,
            "output_step": 1,
            "window_size": 14
        },
        "GRU_bench_mark_1": {
            "hidden_size": 64,
            "output_step": 1,
            "window_size": 14
        }
    },
    "training": {
        "magnitude_1": {
            "device": "cuda",
            "batch_size": 64,
            "num_epoch": 1,
            "learning_rate": 0.001,
            "loss": "mse",
            "evaluate": [
                "mse",
                "mae"
            ],
            "optimizer": "adam",
            "scheduler_step_size": 50,
            "patient": 200,
            "from": "2021-01-01",
            "to": null,
            "best_model": true,
            "early_stop": true,
            "train_shuffle": true,
            "val_shuffle": true,
            "test_shuffle": true
        },
        "LSTM_bench_mark_1": {
            "device": "cuda",
            "batch_size": 64,
            "num_epoch": 1000,
            "learning_rate": 0.01,
            "loss": "bce",
            "evaluate": [
                "bce",
                "accuracy",
                "precision",
                "f1"
            ],
            "optimizer": "adam",
            "scheduler_step_size": 500,
            "patient": 1000,
            "start": "2000-5-01",
            "end": null,
            "best_model": true,
            "early_stop": true,
            "train_shuffle": true,
            "val_shuffle": true,
            "test_shuffle": true,
            "weight_decay": 0.1
        },
        "svm_1": {
            "batch_size": 64,
            "num_epoch": 300,
            "learning_rate": 0.01,
            "loss": "bce",
            "evaluate": [
                "bce",
                "accuracy",
                "precision",
                "f1"
            ],
            "optimizer": "adam",
            "scheduler_step_size": 50,
            "patient": 1000,
            "start": "2022-07-01",
            "end": "2023-05-01",
            "best_model": true,
            "early_stop": true,
            "train_shuffle": true,
            "val_shuffle": true,
            "test_shuffle": true,
            "weight_decay": 0.5
        }
    },
    "pytorch_timeseries_model_type_dict": {
        "1": "movement",
        "2": "magnitude",
        "3": "assembler",
        "4": "lstm",
        "5": "gru",
        "6": "ensembler",
        "7": "pred_price_LSTM"
    },
    "tensorflow_timeseries_model_type_dict": {
        "1": "svm",
        "2": "random_forest",
        "3": "xgboost"
    }
}
Epoch:3
Learning rate:3
{
    "model": {
        "num_layers": 10,
        "hidden_size": 20,
        "drop_out": 0.5,
        "conv1D_param": {
            "type": 1,
            "kernel_size": 4,
            "dilation_base": 3,
            "max_pooling_kernel_size": 2,
            "sub_small_num_layer": 1,
            "sub_big_num_layer": 1,
            "sub_small_kernel_size": 3,
            "sub_big_kernel_size": 30,
            "output_size": 20
        },
        "symbol": "AMZN",
        "topk": 10,
        "data_mode": 1,
        "window_size": 14,
        "output_step": 7,
        "max_string_length": 1000,
        "param_grid": {
            "data_mode": [
                0,
                1,
                2
            ],
            "window_size": [
                3,
                7,
                14
            ],
            "output_size": [
                3,
                7,
                14
            ],
            "drop_out": [
                0.0,
                0.2,
                0.5,
                0.8
            ],
            "max_string_length": [
                500,
                1000,
                10000,
                20000
            ]
        }
    },
    "training": {
        "device": "cuda",
        "batch_size": 64,
        "num_epoch": 50,
        "learning_rate": 0.001,
        "loss": "bce",
        "evaluate": [
            "bce",
            "accuracy",
            "precision",
            "f1"
        ],
        "optimizer": "adam",
        "scheduler_step_size": 50,
        "patient": 100,
        "start": "2022-07-01",
        "end": "2023-05-01",
        "best_model": true,
        "early_stop": true,
        "train_shuffle": true,
        "val_shuffle": true,
        "test_shuffle": true,
        "weight_decay": 0.0001
    }
}
Train evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.59      0.89      0.71        53
          UP       0.33      0.09      0.14        35

    accuracy                           0.57        88
   macro avg       0.46      0.49      0.42        88
weighted avg       0.49      0.57      0.48        88

Confusion matrix:
[[47  6]
 [32  3]]
----------------------------------------------------------------------------------------------------
Train evaluate lstm_AMZN_w14_o7_d1 BCE loss: 49.31221389770508
-----------------------------------------------------------------------------------------------------
Valid evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.38      0.71      0.49        17
          UP       0.17      0.05      0.07        21

    accuracy                           0.34        38
   macro avg       0.27      0.38      0.28        38
weighted avg       0.26      0.34      0.26        38

Confusion matrix:
[[12  5]
 [20  1]]
----------------------------------------------------------------------------------------------------
Valid evaluate lstm_AMZN_w14_o7_d1 BCE loss: 50.77872085571289
-----------------------------------------------------------------------------------------------------
Test evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.36      0.93      0.52        14
          UP       0.86      0.21      0.33        29

    accuracy                           0.44        43
   macro avg       0.61      0.57      0.43        43
weighted avg       0.70      0.44      0.39        43

Confusion matrix:
[[13  1]
 [23  6]]
----------------------------------------------------------------------------------------------------
Test evaluate lstm_AMZN_w14_o7_d1 BCE loss: 49.98386001586914
-----------------------------------------------------------------------------------------------------
Balanced Test evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.59      0.93      0.72        14
          UP       0.83      0.36      0.50        14

    accuracy                           0.64        28
   macro avg       0.71      0.64      0.61        28
weighted avg       0.71      0.64      0.61        28

Confusion matrix:
[[13  1]
 [ 9  5]]
----------------------------------------------------------------------------------------------------
Balanced Test evaluate lstm_AMZN_w14_o7_d1 BCE loss: 49.89202117919922
-----------------------------------------------------------------------------------------------------
2023-06-17 21:51:18{
    "alpha_vantage": {
        "api_key": "XOLA7URKCZHU7C9X",
        "output_size": "full",
        "url": "https://www.alphavantage.co",
        "key_adjusted_close": "5. adjusted close"
    },
    "data": {
        "train_test_split_size": 0.7,
        "train_val_split_size": 0.7,
        "smoothing": 2
    },
    "plots": {
        "show_plots": false,
        "xticks_interval": 90,
        "color_actual_val": "#001f3f",
        "color_actual_test": "#4D1BF3",
        "color_train": "#3D9970",
        "color_val": "#0074D9",
        "color_pred_train": "#3D9970",
        "color_pred_val": "#0074D9",
        "color_pred_test": "#FF4136"
    },
    "model": {
        "magnitude_1": {
            "lstm_num_layers": 4.5,
            "lstm_hidden_layer_size": 64,
            "drop_out": 0.4,
            "output_step": 1,
            "window_size": 14,
            "conv1d_kernel_size": 4,
            "dilation_base": 3
        },
        "LSTM_bench_mark_1": {
            "lstm_num_layer": 1,
            "lstm_hidden_layer_size": 64,
            "drop_out": 0.2,
            "output_step": 1,
            "window_size": 14
        },
        "GRU_bench_mark_1": {
            "hidden_size": 64,
            "output_step": 1,
            "window_size": 14
        }
    },
    "training": {
        "magnitude_1": {
            "device": "cuda",
            "batch_size": 64,
            "num_epoch": 1,
            "learning_rate": 0.001,
            "loss": "mse",
            "evaluate": [
                "mse",
                "mae"
            ],
            "optimizer": "adam",
            "scheduler_step_size": 50,
            "patient": 200,
            "from": "2021-01-01",
            "to": null,
            "best_model": true,
            "early_stop": true,
            "train_shuffle": true,
            "val_shuffle": true,
            "test_shuffle": true
        },
        "LSTM_bench_mark_1": {
            "device": "cuda",
            "batch_size": 64,
            "num_epoch": 1000,
            "learning_rate": 0.01,
            "loss": "bce",
            "evaluate": [
                "bce",
                "accuracy",
                "precision",
                "f1"
            ],
            "optimizer": "adam",
            "scheduler_step_size": 500,
            "patient": 1000,
            "start": "2000-5-01",
            "end": null,
            "best_model": true,
            "early_stop": true,
            "train_shuffle": true,
            "val_shuffle": true,
            "test_shuffle": true,
            "weight_decay": 0.1
        },
        "svm_1": {
            "batch_size": 64,
            "num_epoch": 300,
            "learning_rate": 0.01,
            "loss": "bce",
            "evaluate": [
                "bce",
                "accuracy",
                "precision",
                "f1"
            ],
            "optimizer": "adam",
            "scheduler_step_size": 50,
            "patient": 1000,
            "start": "2022-07-01",
            "end": "2023-05-01",
            "best_model": true,
            "early_stop": true,
            "train_shuffle": true,
            "val_shuffle": true,
            "test_shuffle": true,
            "weight_decay": 0.5
        }
    },
    "pytorch_timeseries_model_type_dict": {
        "1": "movement",
        "2": "magnitude",
        "3": "assembler",
        "4": "lstm",
        "5": "gru",
        "6": "ensembler",
        "7": "pred_price_LSTM"
    },
    "tensorflow_timeseries_model_type_dict": {
        "1": "svm",
        "2": "random_forest",
        "3": "xgboost"
    }
}
Epoch:12
Learning rate:12
{
    "model": {
        "num_layers": 10,
        "hidden_size": 20,
        "drop_out": 0.5,
        "conv1D_param": {
            "type": 1,
            "kernel_size": 4,
            "dilation_base": 3,
            "max_pooling_kernel_size": 2,
            "sub_small_num_layer": 1,
            "sub_big_num_layer": 1,
            "sub_small_kernel_size": 3,
            "sub_big_kernel_size": 30,
            "output_size": 20
        },
        "symbol": "AMZN",
        "topk": 10,
        "data_mode": 1,
        "window_size": 14,
        "output_step": 7,
        "max_string_length": 1000,
        "param_grid": {
            "data_mode": [
                0,
                1,
                2
            ],
            "window_size": [
                3,
                7,
                14
            ],
            "output_size": [
                3,
                7,
                14
            ],
            "drop_out": [
                0.0,
                0.2,
                0.5,
                0.8
            ],
            "max_string_length": [
                500,
                1000,
                10000,
                20000
            ]
        }
    },
    "training": {
        "device": "cuda",
        "batch_size": 64,
        "num_epoch": 50,
        "learning_rate": 0.001,
        "loss": "bce",
        "evaluate": [
            "bce",
            "accuracy",
            "precision",
            "f1"
        ],
        "optimizer": "adam",
        "scheduler_step_size": 50,
        "patient": 100,
        "start": "2022-07-01",
        "end": "2023-05-01",
        "best_model": true,
        "early_stop": true,
        "train_shuffle": true,
        "val_shuffle": true,
        "test_shuffle": true,
        "weight_decay": 0.0001
    }
}
Train evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.62      0.91      0.73        53
          UP       0.50      0.14      0.22        35

    accuracy                           0.60        88
   macro avg       0.56      0.52      0.48        88
weighted avg       0.57      0.60      0.53        88

Confusion matrix:
[[48  5]
 [30  5]]
----------------------------------------------------------------------------------------------------
Train evaluate lstm_AMZN_w14_o7_d1 BCE loss: 49.2837028503418
-----------------------------------------------------------------------------------------------------
Valid evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.44      0.88      0.59        17
          UP       0.50      0.10      0.16        21

    accuracy                           0.45        38
   macro avg       0.47      0.49      0.37        38
weighted avg       0.47      0.45      0.35        38

Confusion matrix:
[[15  2]
 [19  2]]
----------------------------------------------------------------------------------------------------
Valid evaluate lstm_AMZN_w14_o7_d1 BCE loss: 51.0050163269043
-----------------------------------------------------------------------------------------------------
Test evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.30      0.79      0.43        14
          UP       0.50      0.10      0.17        29

    accuracy                           0.33        43
   macro avg       0.40      0.44      0.30        43
weighted avg       0.43      0.33      0.26        43

Confusion matrix:
[[11  3]
 [26  3]]
----------------------------------------------------------------------------------------------------
Test evaluate lstm_AMZN_w14_o7_d1 BCE loss: 50.879844665527344
-----------------------------------------------------------------------------------------------------
Balanced Test evaluate lstm_AMZN_w14_o7_d1
Classification report:
              precision    recall  f1-score   support

        DOWN       0.57      0.86      0.69        14
          UP       0.71      0.36      0.48        14

    accuracy                           0.61        28
   macro avg       0.64      0.61      0.58        28
weighted avg       0.64      0.61      0.58        28

Confusion matrix:
[[12  2]
 [ 9  5]]
----------------------------------------------------------------------------------------------------
Balanced Test evaluate lstm_AMZN_w14_o7_d1 BCE loss: 49.36347198486328
-----------------------------------------------------------------------------------------------------
